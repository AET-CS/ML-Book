Bayes_Theorem_Student.ipynb:    "from matplotlib import pyplot as plt"
Cancer_Logistic_Student.ipynb:    "import pandas as pd\n",
Cancer_Logistic_Student.ipynb:    "import os\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.metrics import r2_score\n",
Cancer_Logistic_Student.ipynb:    "import numpy as np\n",
Cancer_Logistic_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Cancer_Logistic_Student.ipynb:    "import seaborn as sns"
Cancer_Logistic_Student.ipynb:    "import pandas as pd\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.model_selection import train_test_split\n",
Cancer_Logistic_Student.ipynb:    "from sklearn import preprocessing\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.compose import ColumnTransformer\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.pipeline import Pipeline\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.preprocessing import OrdinalEncoder\n",
Cancer_Logistic_Student.ipynb:    "from scipy.stats import chi2_contingency\n"
Cancer_Logistic_Student.ipynb:      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, ConfusionMatrixDisplay\n\u001b[0;32m----> 3\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43msorted_y_test\u001b[49m, observed, labels\u001b[38;5;241m=\u001b[39mlreg\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m      4\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm,\n\u001b[1;32m      5\u001b[0m                               display_labels\u001b[38;5;241m=\u001b[39mlreg\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m      6\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot()\n",
Cancer_Logistic_Student.ipynb:    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
Gaussian_Elimination_Student.ipynb:    "import numpy as np\n",
Gaussian_Elimination_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Hobo_Student.ipynb:    "import pandas as pd\n",
Hobo_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Hobo_Student.ipynb:    "import scipy\n",
Hobo_Student.ipynb:    "import sklearn as sk\n",
Hobo_Student.ipynb:    "import cv2\n",
Hobo_Student.ipynb:    "import numpy as np"
Hobo_Student.ipynb:    "from sklearn.cluster import KMeans\n",
Intro_to_Matrices_in_NumPy.ipynb:    "import numpy as np"
Least_Squares.ipynb:    "import numpy as np\n",
Least_Squares.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Expectancy.ipynb:    "import pandas as pd\n",
Life_Expectancy.ipynb:    "import os\n",
Life_Expectancy.ipynb:    "from sklearn.linear_model import LinearRegression\n",
Life_Expectancy.ipynb:    "from sklearn.metrics import r2_score\n",
Life_Expectancy.ipynb:    "import numpy as np\n",
Life_Expectancy.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Expectancy.ipynb:    "import seaborn as sns\n"
Life_Expectancy.ipynb:    "Which features seem to be important?"
Life_Expectancy.ipynb:    "We're finally ready to do some data modeling using scikit-learn. In this cell we import some methods we'll use, reload the data frame (just to be safe), re-pre-process-it, and one-hot-encode all the categorical variables."
Life_Expectancy.ipynb:    "import pandas as pd\n",
Life_Expectancy.ipynb:    "from sklearn.model_selection import train_test_split\n",
Life_Expectancy.ipynb:    "from sklearn.preprocessing import LabelEncoder\n",
Life_Expectancy.ipynb:    "from sklearn.tree import DecisionTreeClassifier\n",
Life_Expectancy.ipynb:    "from sklearn.metrics import accuracy_score, classification_report"
Life_Expectancy.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Expectancy.ipynb:    "from sklearn.compose import ColumnTransformer\n",
Life_Expectancy.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Expectancy.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
Life_Expectancy.ipynb:    "from sklearn.pipeline import Pipeline\n",
Life_Expectancy.ipynb:    "from sklearn.preprocessing import OrdinalEncoder\n",
Life_Expectancy.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Expectancy.ipynb:    "import pandas as pd\n",
Life_Expectancy.ipynb:    "import statsmodels.api as sm\n",
Life_Expectancy_Student.ipynb:    "import pandas as pd\n",
Life_Expectancy_Student.ipynb:    "import os\n",
Life_Expectancy_Student.ipynb:    "from sklearn.linear_model import LinearRegression\n",
Life_Expectancy_Student.ipynb:    "from sklearn.metrics import r2_score\n",
Life_Expectancy_Student.ipynb:    "import numpy as np\n",
Life_Expectancy_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Expectancy_Student.ipynb:    "import seaborn as sns\n"
Life_Expectancy_Student.ipynb:    "Which features seem to be important?"
Life_Expectancy_Student.ipynb:    "import pandas as pd\n",
Life_Expectancy_Student.ipynb:    "from sklearn.model_selection import train_test_split\n",
Life_Expectancy_Student.ipynb:    "from sklearn.preprocessing import LabelEncoder\n",
Life_Expectancy_Student.ipynb:    "from sklearn.tree import DecisionTreeClassifier\n",
Life_Expectancy_Student.ipynb:    "from sklearn.metrics import accuracy_score, classification_report\n",
Life_Expectancy_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Expectancy_Student.ipynb:    "from sklearn.compose import ColumnTransformer\n",
Life_Expectancy_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Expectancy_Student.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
Life_Expectancy_Student.ipynb:    "from sklearn.pipeline import Pipeline\n",
Life_Expectancy_Student.ipynb:    "from sklearn.preprocessing import OrdinalEncoder"
Life_Expectancy_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Expectancy_Student.ipynb:    "import pandas as pd\n",
Life_Expectancy_Student.ipynb:    "import statsmodels.api as sm\n",
Life_Part_2.ipynb:    "Last class we created a linear model for the WHO life expectancy database. Today we will focus on various ways to interpret the model and refine it, specifically by interpreting the importance of each model feature and selecting a subset of features that make our model more interpretable and more extensible.\n",
Life_Part_2.ipynb:    "import pandas as pd\n",
Life_Part_2.ipynb:    "import os\n",
Life_Part_2.ipynb:    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
Life_Part_2.ipynb:    "from sklearn.metrics import r2_score\n",
Life_Part_2.ipynb:    "import numpy as np\n",
Life_Part_2.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Part_2.ipynb:    "import seaborn as sns"
Life_Part_2.ipynb:    "import pandas as pd\n",
Life_Part_2.ipynb:    "from sklearn.model_selection import train_test_split\n",
Life_Part_2.ipynb:    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
Life_Part_2.ipynb:    "from sklearn.compose import ColumnTransformer\n",
Life_Part_2.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Part_2.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
Life_Part_2.ipynb:    "from sklearn.preprocessing import OrdinalEncoder"
Life_Part_2.ipynb:    "Look closely at this graph. We discussed how the coefficient here is a measure of importance. If, for example, `HIV/AIDS` increases by one unit, then the life expectancy should decrease by about 0.5 units. Of course the units vary from feature to feature. So comparing these coefficients directly is basically impossible. We'll fix this in the next section.\n",
Life_Part_2.ipynb:    "This has the interesting mathematical effect of not just decreasing the magnitude of coefficient but actually driving coefficients to zero. The result is that the remaining features with non-zero coefficients can be interpreted as \"most important\" and lead to a simpler model with similar accuracy to a larger model."
Life_Part_2.ipynb:    "import warnings\n",
Life_Part_2_Student.ipynb:    "Last class we created a linear model for the WHO life expectancy database. Today we will focus on various ways to interpret the model and refine it, specifically by interpreting the importance of each model feature and selecting a subset of features that make our model more interpretable and more extensible.\n",
Life_Part_2_Student.ipynb:    "import pandas as pd\n",
Life_Part_2_Student.ipynb:    "import os\n",
Life_Part_2_Student.ipynb:    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
Life_Part_2_Student.ipynb:    "from sklearn.metrics import r2_score\n",
Life_Part_2_Student.ipynb:    "import numpy as np\n",
Life_Part_2_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Life_Part_2_Student.ipynb:    "import seaborn as sns"
Life_Part_2_Student.ipynb:    "import pandas as pd\n",
Life_Part_2_Student.ipynb:    "from sklearn.model_selection import train_test_split\n",
Life_Part_2_Student.ipynb:    "from sklearn import preprocessing\n",
Life_Part_2_Student.ipynb:    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
Life_Part_2_Student.ipynb:    "from sklearn.metrics import accuracy_score, classification_report\n",
Life_Part_2_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Part_2_Student.ipynb:    "from sklearn.compose import ColumnTransformer\n",
Life_Part_2_Student.ipynb:    "from sklearn.impute import SimpleImputer\n",
Life_Part_2_Student.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
Life_Part_2_Student.ipynb:    "from sklearn.pipeline import Pipeline\n",
Life_Part_2_Student.ipynb:    "from sklearn.preprocessing import OrdinalEncoder"
Life_Part_2_Student.ipynb:    "Look closely at this graph. We discussed how the coefficient here is a measure of importance. If, for example, `HIV/AIDS` increases by one unit, then the life expectancy should decrease by about 0.5 units. Of course the units vary from feature to feature. So comparing these coefficients directly is basically impossible. We'll fix this in the next section.\n",
Life_Part_2_Student.ipynb:    "This has the interesting mathematical effect of not just decreasing the magnitude of coefficient but actually driving coefficients to zero. The result is that the remaining features with non-zero coefficients can be interpreted as \"most important\" and lead to a simpler model with similar accuracy to a larger model."
LogLogRegression.ipynb:    "import numpy as np\n",
LogLogRegression.ipynb:    "import matplotlib.pyplot as plt"
LogLogRegression.ipynb:    "import random"
Matrices_Index_Warmup_Student.ipynb:    "import numpy as np"
Matrices_Student.ipynb:    "This notebook will review some important concepts in linear algebra while helping you practice working with lists and nested lists in Python. You will provide code cells as needed to complete the sections below. Testing code is provided for you to help check that your methods perform as expected."
Matrices_Student.ipynb:    "import numpy as np\n",
Matrices_Student.ipynb:    "from matplotlib import pyplot as plt\n",
Matrices_Student.ipynb:    "import math"
Matrices_Student.ipynb:    "A very important result from linear algebra used in machine learning relates the angle between two vectors. You will derive this yourself. Given **a** and **b**, you can form a triangle where the vectors share the same tail. The vector forming the third side is the vector **a-b**. Find the length of this third side in terms of **a** and **b**. Hint: use the law of cosines. Hint: dot product distributes like 'times'"
Mushroom_Bayes.ipynb:    "import numpy as np\n",
Mushroom_Bayes.ipynb:    "import matplotlib.pyplot as plt\n",
Mushroom_Bayes.ipynb:    "from sklearn.datasets import make_classification\n",
Mushroom_Bayes.ipynb:    "from sklearn.model_selection import train_test_split\n",
Mushroom_Bayes.ipynb:    "from sklearn.neighbors import KNeighborsClassifier\n",
Mushroom_Bayes.ipynb:    "from sklearn.metrics import accuracy_score\n",
Mushroom_Bayes.ipynb:    "import pandas as pd"
Mushroom_Key.ipynb:    "import pandas as pd\n",
Mushroom_Key.ipynb:    "import os"
Mushroom_Key.ipynb:    "import seaborn as sns\n",
Mushroom_Key.ipynb:    "from matplotlib import pyplot as plt\n",
Mushroom_Key.ipynb:    "import pandas as pd\n",
Mushroom_Key.ipynb:    "from sklearn.feature_selection import chi2\n",
Mushroom_Key.ipynb:    "from sklearn.preprocessing import LabelEncoder"
Mushroom_Key.ipynb:    "import seaborn as sns\n",
Mushroom_Key.ipynb:    "import pandas as pd\n",
Mushroom_Key.ipynb:    "from sklearn.model_selection import train_test_split\n",
Mushroom_Key.ipynb:    "from sklearn.preprocessing import LabelEncoder\n",
Mushroom_Key.ipynb:    "from sklearn.tree import DecisionTreeClassifier\n",
Mushroom_Key.ipynb:    "from sklearn.metrics import accuracy_score, classification_report\n",
Mushroom_Key.ipynb:    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
Mushroom_Key.ipynb:    "from sklearn.ensemble import RandomForestClassifier\n",
Mushroom_Key.ipynb:    "from sklearn.svm import SVC\n",
Mushroom_Key.ipynb:    "from sklearn.linear_model import LogisticRegression\n",
Mushroom_Key.ipynb:    "from sklearn.neighbors import KNeighborsClassifier\n",
Mushroom_Key.ipynb:    "from sklearn.ensemble import GradientBoostingClassifier\n",
Mushroom_Key.ipynb:    "from sklearn.neural_network import MLPClassifier\n",
Mushroom_Student.ipynb:    "import pandas as pd\n",
Mushroom_Student.ipynb:    "import os"
Mushroom_Student.ipynb:    "import seaborn as sns\n",
Mushroom_Student.ipynb:    "from matplotlib import pyplot as plt\n",
Mushroom_Student.ipynb:    "import pandas as pd\n",
Mushroom_Student.ipynb:    "import numpy as np\n",
Mushroom_Student.ipynb:    "import seaborn as sns\n",
Mushroom_Student.ipynb:    "import matplotlib.pyplot as plt\n",
Mushroom_Student.ipynb:    "from scipy.stats import chi2_contingency\n",
Mushroom_Student.ipynb:    "Which features seem to be important?"
Mushroom_Student.ipynb:    "We're finally ready to do some data modeling using scikit-learn. In this cell we import some methods we'll use, reload the data frame (just to be safe), re-pre-process-it, and one-hot-encode all the categorical variables."
Mushroom_Student.ipynb:    "import pandas as pd\n",
Mushroom_Student.ipynb:    "from sklearn.model_selection import train_test_split\n",
Mushroom_Student.ipynb:    "from sklearn.preprocessing import LabelEncoder\n",
Mushroom_Student.ipynb:    "from sklearn.tree import DecisionTreeClassifier\n",
Mushroom_Student.ipynb:    "from sklearn.metrics import accuracy_score, classification_report\n",
Mushroom_Student.ipynb:    "There are many metrics for evaluating categorical models, and they are sometimes at odds. Accuracy is simplistic and obscures what could be more important -- are there more false positives or more false negatives? And which is more important? In a task to identify poisonous mushrooms, a false negative (labeling a 'p' as an 'e') is deadly. The \"recall\" on \"p\" below captures this value. This measures the percent of poisonous mushrooms you have correctly labeled as poisonous.\n",
Mushroom_Student.ipynb:    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
Mushroom_Student.ipynb:    "from sklearn.ensemble import RandomForestClassifier\n",
Mushroom_Student.ipynb:    "from sklearn.svm import SVC\n",
Mushroom_Student.ipynb:    "from sklearn.linear_model import LogisticRegression\n",
Mushroom_Student.ipynb:    "from sklearn.neighbors import KNeighborsClassifier\n",
Mushroom_Student.ipynb:    "from sklearn.ensemble import GradientBoostingClassifier\n",
Mushroom_Student.ipynb:    "from sklearn.neural_network import MLPClassifier\n",
PCA.ipynb:    "import pandas as pd\n",
PCA.ipynb:    "from sklearn.model_selection import train_test_split\n",
PCA.ipynb:    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
PCA.ipynb:    "from sklearn.compose import ColumnTransformer\n",
PCA.ipynb:    "from sklearn.impute import SimpleImputer\n",
PCA.ipynb:    "from sklearn.preprocessing import OneHotEncoder\n",
PCA.ipynb:    "from sklearn.preprocessing import OrdinalEncoder\n",
PCA.ipynb:    "import numpy as np"
PCA.ipynb:    "import os\n",
PCA.ipynb:    "import pandas as pd\n",
PCA.ipynb:    "import pandas as pd\n",
PCA.ipynb:    "from sklearn.decomposition import PCA\n",
PCA.ipynb:    "from sklearn.preprocessing import StandardScaler\n",
PCA.ipynb:    "import matplotlib.pyplot as plt\n",
PCA Matrices.ipynb:    "import numpy as np\n",
PCA Matrices.ipynb:    "import matplotlib.pyplot as plt\n"
PCA Matrices.ipynb:    "import numpy as np\n",
PCA Matrices.ipynb:    "import matplotlib.pyplot as plt\n",
PCA Matrices.ipynb:    "import numpy as np\n",
PCA Matrices.ipynb:    "import matplotlib.pyplot as plt\n",
PCA Matrices.ipynb:    "import cv2"
PCA Matrices.ipynb:    "from PIL import Image\n",
PCA Matrices.ipynb:    "import numpy as np\n",
Running_Time_Analysis.ipynb:    "import pandas as pd\n",
Running_Time_Analysis.ipynb:    "import numpy as np"
Weather.ipynb:    "import pandas as pd"
weather-teacher.ipynb:    "import pandas as pd\n",
weather-teacher.ipynb:    "import pytz"
weather-teacher.ipynb:    "from astral.sun import sun\n",
weather-teacher.ipynb:    "from astral import LocationInfo\n",
weather-teacher.ipynb:    "from datetime import date\n",
